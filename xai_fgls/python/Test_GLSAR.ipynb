{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pickled model from ../models/MNIST/LeNet-5.nn\n",
      "output layer is not softmax. nothing to do\n",
      "loading np-formatted data from ../data/MNIST/test_images.npy\n",
      "loading np-formatted data from ../data/MNIST/test_labels.npy\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import time\n",
    "import numpy as np\n",
    "import importlib.util as imp\n",
    "if imp.find_spec(\"cupy\"): #use cupy for GPU support if available\n",
    "    import cupy\n",
    "    import cupy as np\n",
    "\n",
    "\n",
    "import model_io\n",
    "import data_io\n",
    "import render\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "#load a neural network, as well as the MNIST test data and some labels\n",
    "nn = model_io.read('../models/MNIST/LeNet-5.nn') # 99.23% prediction accuracy\n",
    "\n",
    "nn.drop_softmax_output_layer() #drop softnax output layer for analyses\n",
    "\n",
    "X = data_io.read('../data/MNIST/test_images.npy')\n",
    "Y = data_io.read('../data/MNIST/test_labels.npy')\n",
    "\n",
    "\n",
    "# transfer pixel values from [0 255] to [-1 1] to satisfy the expected input / training paradigm of the model\n",
    "# 픽셀 벨류를 0 ~ 255인 애들에서 -1과 1의 값으로 변경\n",
    "X =  X / 127.5 - 1.\n",
    "\n",
    "#reshape the vector representations in X to match the requirements of the CNN input\n",
    "# CNN에 들어갈 수 있도록 Vector를 Reshape(array로)\n",
    "X = np.reshape(X,[X.shape[0],28,28,1])\n",
    "# 패딩 진행\n",
    "X = np.pad(X,((0,0),(2,2),(2,2),(0,0)), 'constant', constant_values = (-1.,))\n",
    "\n",
    "# transform numeric class labels to vector indicator for uniformity. assume presence of all classes within the label set\n",
    "# 클래스를 Label화 시키기 위해 Unique 값 지정 및 0으로 초기화\n",
    "I = Y[:,0].astype(int)\n",
    "Y = np.zeros([X.shape[0],np.unique(Y).size])\n",
    "Y[np.arange(Y.shape[0]),I] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model test accuracy is: 0.9924\n"
     ]
    }
   ],
   "source": [
    "acc = np.mean(np.argmax(nn.forward(X), axis=1) == np.argmax(Y, axis=1))\n",
    "# 가장 높은 값의 평균을 가져오고, 예측값 진행(argmax) forward는 pytorch로 코딩한 것.\n",
    "if not np == numpy: # np=cupy\n",
    "    acc = np.asnumpy(acc)\n",
    "print('model test accuracy is: {:0.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = np.arange(X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Class:      7\n",
      "Predicted Class: 7 \n",
      "\n",
      "True Class:      2\n",
      "Predicted Class: 2 \n",
      "\n",
      "True Class:      1\n",
      "Predicted Class: 1 \n",
      "\n",
      "True Class:      0\n",
      "Predicted Class: 0 \n",
      "\n",
      "True Class:      4\n",
      "Predicted Class: 4 \n",
      "\n",
      "True Class:      1\n",
      "Predicted Class: 1 \n",
      "\n",
      "True Class:      4\n",
      "Predicted Class: 4 \n",
      "\n",
      "True Class:      9\n",
      "Predicted Class: 9 \n",
      "\n",
      "True Class:      5\n",
      "Predicted Class: 5 \n",
      "\n",
      "True Class:      9\n",
      "Predicted Class: 9 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in I[:10]:\n",
    "    # i의 순번을 지정하고\n",
    "    x = X[i:i+1,...]\n",
    "\n",
    "    #forward pass and prediction\n",
    "    # 예측하고\n",
    "    ypred = nn.forward(x)\n",
    "    print('True Class:     ', np.argmax(Y[i]))\n",
    "    print('Predicted Class:', np.argmax(ypred),'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'get_activations'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-aef63120d3bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_activations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'get_activations'"
     ]
    }
   ],
   "source": [
    "nn.get_activations(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    #prepare initial relevance to reflect the model's dominant prediction (ie depopulate non-dominant output neurons)\n",
    "    # zeros_like를 사용해서 다른 배열과 같은 크기의 배열을 0로 생성하고\n",
    "    mask = np.zeros_like(ypred)\n",
    "    # argmax를 사용해서 가장 큰 값 가져오고\n",
    "    mask[:,np.argmax(ypred)] = 1\n",
    "    # 초기 Relevance Score 지정하고\n",
    "    Rinit = ypred*mask\n",
    "\n",
    "\n",
    "    #compute first layer relevance according to prediction\n",
    "    #R = nn.lrp(Rinit)                   #as Eq(56) from DOI: 10.1371/journal.pone.0130140\n",
    "    R = nn.lrp(Rinit,'epsilon',1.)\n",
    "\n",
    "    R = R.sum(axis=3)\n",
    "    xs = ((x+1.)/2.).sum(axis=3)\n",
    "\n",
    "    if not np == numpy: \n",
    "        xs = np.asnumpy(xs)\n",
    "        R = np.asnumpy(R)\n",
    "\n",
    "    digit = render.digit_to_rgb(xs, scaling = 3)\n",
    "    hm = render.hm_to_rgb(R, X = xs, scaling = 3, sigma = 2)\n",
    "    digit_hm = render.save_image([digit,hm],'../heatmap.png')\n",
    "    data_io.write(R,'../heatmap.npy')\n",
    "    \n",
    "    y = R\n",
    "    a = np.load('../convolution.npy')\n",
    "    a = np.reshape(a,[a.shape[1]*a.shape[2],1])\n",
    "    b = np.load('../sumpoll.npy')\n",
    "    b = np.pad(b,((0,0),(2,2),(2,2),(0,0)))\n",
    "    b = np.reshape(b,[b.shape[1]*b.shape[2],b.shape[3]])\n",
    "    c = np.load('../rect.npy')    \n",
    "    c = np.pad(c,((0,0),(2,2),(2,2),(0,0)))\n",
    "    c = np.reshape(c,[c.shape[1]*c.shape[2],c.shape[3]])\n",
    "    \n",
    "    new_b = np.hstack((b, c))\n",
    "    new = np.hstack((a, new_b))\n",
    "    y = np.reshape(y, [y.shape[0]*y.shape[1]*y.shape[2]])\n",
    "    y_tran = y.transpose()\n",
    "    new = sm.add_constant(new)\n",
    "    new = np.nan_to_num(new)\n",
    "    y = np.nan_to_num(y)\n",
    "    model = sm.GLSAR(y_tran, new, rho = 4, missing = \"raise\")\n",
    "    for i in range(2):\n",
    "        result = model.fit()\n",
    "        print(\"AR coefficients : {0}\".format(model.rho))\n",
    "        rho, sigma = sm.regression.yule_walker(result.resid, order = model.order)\n",
    "        print(\"{}step is done\".format(i))\n",
    "        model = sm.GLSAR(y_tran, new, rho)\n",
    "    find = result.resid\n",
    "    check = np.reshape(find,[1,32,32])\n",
    "    \n",
    "    digit = render.digit_to_rgb(xs, scaling = 3)\n",
    "    hm_R = render.hm_to_rgb(check, X = xs, scaling = 3, sigma = 2)\n",
    "    digit_hm = render.save_image([digit,hm, hm_R],'../re_heatmap.png')\n",
    "    data_io.write(check,'../re_heatmap.npy')\n",
    "    \n",
    "\n",
    "    plt.imshow(digit_hm, interpolation = 'none')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai",
   "language": "python",
   "name": "xai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
